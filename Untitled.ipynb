{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import calculate_log as callog\n",
    "import torch\n",
    "import argparse\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class opt:\n",
    "    outf = 'extracted_features'\n",
    "    backbone_name = 'resnet18_vanilla_simclr_cifar100'\n",
    "    dataset ='cifar100'\n",
    "    out_dataset = 'svhn'\n",
    "    fet = '_mean'\n",
    "    aug = ''\n",
    "    \n",
    "ood_dataset=[opt.out_dataset,'lsun_resize','imagenet_resize'] \n",
    "#augs = ['','_cjitter', '_gray', '_hflip', '_vflip']\n",
    "augs = ['']       \n",
    "out_dataset=ood_dataset\n",
    "num_out_datasets = len(ood_dataset)\n",
    "\n",
    "ind_dataset=opt.dataset\n",
    "experiment = opt.backbone_name\n",
    "ae_type = opt.ae_type\n",
    "prefix = opt.prefix #confidence\n",
    "layer_num=9\n",
    "epoch=opt.epoch\n",
    "\n",
    "\n",
    "for idx, aug in enumerate(augs):\n",
    "    if idx == 0:\n",
    "        ind=[]\n",
    "        ind_train=[]\n",
    "        ood=dict()\n",
    "        for i in range(layer_num):\n",
    "            ood[i]=[]\n",
    "            print(os.path.join('trained_autoencoders',ae_type,experiment,'{}_layer_{}_in_{}_epoch_{}{}{}.txt'.format(prefix, i,ind_dataset,epoch, opt.fet, aug)))\n",
    "            ind.append(np.loadtxt(os.path.join('trained_autoencoders',ae_type,experiment,'{}_layer_{}_in_{}_epoch_{}{}{}.txt'.format(prefix, i,ind_dataset,epoch, opt.fet, aug))))\n",
    "            ind_train.append(np.loadtxt(os.path.join('trained_autoencoders',ae_type,experiment,'{}_layer_{}_in_{}_epoch_{}{}_train{}.txt'.format(prefix, i,ind_dataset,epoch, opt.fet, aug))))\n",
    "            for j in range(len(ood_dataset)):\n",
    "                ood[i].append(np.loadtxt(os.path.join('trained_autoencoders',ae_type,experiment,'{}_layer_{}_out_{}_epoch_{}{}_model1{}.txt'.format(prefix, i,ood_dataset[j],epoch, opt.fet, aug))))\n",
    "    else:\n",
    "        for i in range(layer_num):\n",
    "            ind[i] += np.loadtxt(os.path.join('trained_autoencoders',ae_type,experiment,'{}_layer_{}_in_{}_epoch_{}{}{}.txt'.format(prefix, i,ind_dataset,epoch, opt.fet, aug)))\n",
    "            ind_train[i] += np.loadtxt(os.path.join('trained_autoencoders',ae_type,experiment,'{}_layer_{}_in_{}_epoch_{}{}_train{}.txt'.format(prefix, i,ind_dataset,epoch, opt.fet, aug)))\n",
    "            for j in range(len(ood_dataset)):\n",
    "                ood[i][j] += np.loadtxt(os.path.join('trained_autoencoders',ae_type,experiment,'{}_layer_{}_out_{}_epoch_{}{}_model1{}.txt'.format(prefix, i,ood_dataset[j],epoch, opt.fet, aug)))\n",
    "                print(ind[i].shape,ood[i][j].shape)\n",
    "ind_scaled=[]\n",
    "ood_scaled=dict()\n",
    "for j in range(len(ood_dataset)):\n",
    "    ood_scaled[j]=[]\n",
    "\n",
    "for i in range(layer_num):\n",
    "    scaler=StandardScaler()\n",
    "    scaler.fit(ind_train[i].reshape(-1,1))\n",
    "    ind_scaled.append(scaler.transform(ind[i].reshape(-1,1)).reshape(-1))\n",
    "    for j in range(len(ood_dataset)):\n",
    "        ood_scaled[j].append(scaler.transform(ood[i][j].reshape(-1,1)).reshape(-1))\n",
    "        \n",
    "        \n",
    "ind_scaled_max=np.min(ind_scaled,0)\n",
    "ood_scaled_max=[]\n",
    "for j in range(len(ood_dataset)):\n",
    "    ood_scaled_max.append(np.min(ood_scaled[j],0))\n",
    "        \n",
    "ood_index= 0\n",
    "print(ood_dataset[ood_index])\n",
    "rst,_,_ = callog.metric(ind_scaled_max,ood_scaled_max[ood_index])\n",
    "# print(rst)\n",
    "print(\"{:.2f} / {:.2f} / {:.2f}\".format(100*rst['TMP']['TNR'],100*rst['TMP']['AUROC'],100*rst['TMP']['DTACC']))\n",
    "\n",
    "ood_index= 1\n",
    "print(ood_dataset[ood_index])\n",
    "rst,_,_ = callog.metric(ind_scaled_max,ood_scaled_max[ood_index])\n",
    "# print(rst)\n",
    "print(\"{:.2f} / {:.2f} / {:.2f}\".format(100*rst['TMP']['TNR'],100*rst['TMP']['AUROC'],100*rst['TMP']['DTACC']))\n",
    "\n",
    "\n",
    "ood_index= 2\n",
    "print(ood_dataset[ood_index])\n",
    "rst,_,_ = callog.metric(ind_scaled_max,ood_scaled_max[ood_index])\n",
    "# print(rst)\n",
    "print(\"{:.2f} / {:.2f} / {:.2f}\".format(100*rst['TMP']['TNR'],100*rst['TMP']['AUROC'],100*rst['TMP']['DTACC']))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ood",
   "language": "python",
   "name": "ood"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
